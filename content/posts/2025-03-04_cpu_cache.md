+++
title = "Cpu cache and you"
date = 2025-03-06
draft = false
+++

Since you can't control (directly) what data goes into the CPU cache, 
model the data so it is cache friendly.

This means grouping data that is frequently used together in contiguous memory, and avoiding storing
unnecessary data together.

Generally the L1 and L2 cache is per core, whereas the L3 cache is shared.
This is not true for older CPUs and is of course not guaranteed to be the case
in the future.

## Testing for cache hits and misses 

It is not possible to observe what is present in the CPU cache, however
it is possible with tools like `perf` to monitor cache misses (and hits).

Since the L1 cache used in the configuration below has both an instruction and
data cache it is possible to monitor these using the following command:

{% note() %}
`perf` is Linux only
{% end %}

```
perf stat -e L1-dcache-load-misses,\
L1-dcache-load,\
L1-icache-load,\
L1-icache-load-misses \
target/release/<program>
```

## Example

This example is demonstrating the performance difference of being able to load
as much relevant data into the CPU cache as possible.

Real world use cases will of course differ, and requirements might not be as
simple as being able to group all the data as per this example.

Here are two structs: `Person1` and `Person2`.
The first type stores age on the type.
The second type stores an index to the age.

{% note() %}
The timings of this is done with a simple wall clock and it's a bit na√Øve, but
should be sufficient to demonstrate the differences.
```
Total number of persons: 64,000,000
Passing every Person1: 69.733526ms
Passing only ages    :  2.452411ms
```
{% end %}

```rust
use std::time::Instant;

type Index = usize;

pub struct Person1 {
    age: u8,
    address_id: Index,
    name: Index,
}

pub struct Person2 {
    age: Index,
    address_id: Index,
    name: Index,
}

// -----------------------------------------------------------------------------
//   - Age persons 1 -
// -----------------------------------------------------------------------------
fn age1(people: &mut [Person1]) {
    for p in people {
        p.age += 1;
    }
}

// -----------------------------------------------------------------------------
//   - Age persons 2 -
// -----------------------------------------------------------------------------
fn age2(ages: &mut [u8]) {
    for a in ages {
        *a += 1;
    }
}

// -----------------------------------------------------------------------------
//   - Setup and run -
//   This creates 64,000,000 `Person`s and increment their ages by one
// -----------------------------------------------------------------------------
pub fn run() {
    const NO_PEOPLE: usize = 64 * 1_000_000;

    // -----------------------------------------------------------------------------
    //   - Persons 1 -
    // -----------------------------------------------------------------------------
    let mut people1 = (0..NO_PEOPLE)
        .map(|age| Person1 {
            age: (age % u8::MAX as usize) as u8,
            address_id: 0,
            name: 0,
        })
        .collect::<Vec<_>>();

    let t1 = Instant::now();
    age1(&mut people1);
    let t1 = t1.elapsed();

    // -----------------------------------------------------------------------------
    //   - Persons 2 -
    // -----------------------------------------------------------------------------
    let mut ages = (0..NO_PEOPLE).map(|age| (age % u8::MAX as usize) as u8).collect::<Vec<u8>>();
    let people2 = (0..NO_PEOPLE)
        .map(|age_idx| Person2 {
            age: age_idx as usize,
            address_id: 0,
            name: 0,
        })
        .collect::<Vec<_>>();

    let t2 = Instant::now();
    age2(&mut ages);
    let t2 = t2.elapsed();

    // -----------------------------------------------------------------------------
    //   - Print the timing -
    // -----------------------------------------------------------------------------
    println!("{:?}", t1);
    println!("{:?}", t2);
}
```
